You are given a number of magnitude 1. You need to divide this number into as many positive parts as possible such that at any moment given a part A, you can divide into only two parts B and C, such that B does not exceed C times some constant. Input: One floating-point number, 1 ≤ k ≤ 1.999, meaning the stated constant factor. The number will have at most 3 digits after the decimal point. Output: First, you should output n, the maximal achievable number of parts for the given value of the constant factor. Then, you should output any proof that this number of parts is in fact achievable: n-1 descriptions of dividing, using the following notation. At each step, you print two numbers: first, the index of the part that you want to divide into two; second, the length of the new number formed. It is assumed that the starting number has index 0. Each newly created number will be given the lowest possible free integer index (so, at the ith step this will be i). -----Example----- Input: 1.5 Output: 4 0 0.4 0 0.3 1 0.2