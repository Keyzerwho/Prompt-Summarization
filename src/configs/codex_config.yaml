header: "Python 3\n"
# If true then we could select model generated problems to generate code for
# Only used if numPrompts < len(promptFile)
# Also, allows only human generated problems for few shotting.
humanOnly: True
promptFile: gpt_generated.txt
# numPrompts is the number of prompts to generate code for
# if numPrompts == -1 then we use all prompts in promptFile
numPrompts: -1
# numExamples is the number of examples prepended to each example
numExamples: 0
summaryType: expert
includeOrig: True  # If True then we will test the original prompt as well
# Codex achieves better results when formatting prompt as docstring
promptPrefix: "\"\"\""
promptSuffix: "\"\"\""
codePrefix:   "def code():"
fewShotSuffix: "\n\n"

apiParams:
  engine: "davinci-codex"
  temperature: 0.0
  max_tokens: 1024
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  stop:
      - "\"\"\""
